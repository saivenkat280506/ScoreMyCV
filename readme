## ScoreMyCV

### Overview
ScoreMyCV is a simple machine learning pipeline that scores resumes based on:
- **Category**: the target role (e.g., "Backend Developer")
- **Resume**: the free‑text resume content

Under the hood, it uses a scikit‑learn `Pipeline` with:
- **One‑Hot Encoding** for `Category`
- **TF‑IDF Vectorization** for `Resume`
- **RandomForestRegressor** to predict a numeric score

The trained model is saved as `score_model.pkl` for reuse.

### Project structure
- `ScoreMyCV.py`: trains the model and makes a sample prediction
- `data_gen.py`: splits an existing dataset into `train_data.json` and `test_data.json`
- `train_data.json`: training samples (JSON list)
- `test_data.json`: held‑out samples (JSON list)
- `score_model.pkl`: saved scikit‑learn pipeline (created after training)
- `app/build.gradle`: placeholder (unrelated to Python pipeline)
- `readme`: this file

### Requirements
- Python 3.9+ recommended
- pip

Python packages:
- scikit‑learn
- pandas
- joblib

Install them with:
```bash
pip install scikit-learn pandas joblib
```

If you prefer isolating dependencies:
```bash
python -m venv .venv
# Windows (PowerShell)
.\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install scikit-learn pandas joblib
```

### Data format
Both `train_data.json` and `test_data.json` are JSON arrays of objects.
- Training requires fields: `Category` (string), `Resume` (string), `Score` (number)
- Example item:
```json
{
  "Category": "Backend Developer",
  "Resume": "Experienced in REST APIs, Python, Django, PostgreSQL",
  "Score": 78.5
}
```

### Generate train/test split (optional)
If you already have a combined dataset in `train_data.json`, you can create a split via:
```bash
python data_gen.py
```
This will rewrite `train_data.json` with ~80% of the data and create `test_data.json` with ~20%.

### Train the model and run a sample prediction
Run:
```bash
python ScoreMyCV.py
```
What it does:
- Loads `train_data.json`
- Builds and fits the pipeline
- Saves the model to `score_model.pkl`
- Loads the saved model and prints a predicted score for a hardcoded example resume

### Use the saved model for your own predictions
After training, you can load `score_model.pkl` and predict on your data:
```python
import joblib
import pandas as pd

model = joblib.load("score_model.pkl")

samples = [
    {"Category": "Backend Developer", "Resume": "Python, FastAPI, PostgreSQL, Docker, AWS"},
    {"Category": "Data Scientist", "Resume": "Pandas, Scikit-Learn, NLP, XGBoost, ML Ops"}
]

df = pd.DataFrame(samples)
preds = model.predict(df)
print(preds)
```

### Notes and tips
- The TF‑IDF vectorizer is configured as unigrams with up to 3000 features and English stop‑words.
- RandomForest parameters can be tuned in `ScoreMyCV.py` (e.g., `n_estimators`, `random_state`).
- Ensure your `Category` values at prediction time are present or handled via `handle_unknown='ignore'` (already enabled).

### Troubleshooting
- If scikit‑learn fails to install from source on Windows, ensure you have a recent pip and a compatible Python version. Prebuilt wheels are usually available for stable Python versions.
- Verify that `train_data.json` is valid JSON and contains the required fields.

### License
No license specified. Add one if you plan to share or open‑source this project.

### Acknowledgments
- Built with scikit‑learn, pandas, and joblib.
